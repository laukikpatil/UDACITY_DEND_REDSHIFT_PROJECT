# Sparkify Analysis Dataload to Redshidt

This project is part of Udacity Data Engineering Nanodegree. 
The objective of the project is 
- Design a dimensional schema in AWS Redshift
- Design staging tables for song data and log data
- Design the ETL process to load data from song meta data and log data files stored in AWS S3.


## Available Data

- Song Dataset
The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song.

- Log Dataset
The second dataset consists of log files in JSON format generated by an event simulator based on the songs in the dataset above. These simulate app activity logs from a music streaming app based on specified configurations.

The log files in the dataset are partitioned by year and month. 

# Project Files

- dwh.cfg
Configuration file used to store all the values that are used by the other project files.

- redshift_setup.ipynb
1. This iPython file connects to AWS using the credentials from the the configuration file.
2. Setup a redshift cluster witht the database required for the project. 
3. Create IAM role and assign policy to the role to read from s3 bucket.
4. Connect to the udacity s3 bucket.
5. Write the role ARN and cluster endpoint back to the config file.
6. Once the ETL execution is complete tear down the infrastructure created in AWS.

- sql_queries.py
Contains all the sql queries used for the project
1. create staging tables
2. create dimension and fact tables
3. copy commands to load data to the staging tables.
4. Insert statements to load data to dimension and fact tables.

- create_tables.py
Drops and creates the tables. Run this file to reset the tables before running ETL scripts.

- etl.py 
Reads and processes files from song_data and log_data and loads them into tables. This is created out based on the work in the ETL notebook.

- README.md 
Provides discussion on the project.


## Database

The database is implemented in Postgresql, i sparkifydb database. Below are the tables in the project

### Staging tables
- staging_events
Event data is loaded from the log files to this staging table.
(artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId)

- staging_songs
Song metadata is loaded in this table.
(num_songs, artist_id, artist_latitude, artist_longitude, artist_location, artist_name, song_id, title, duration, year)

### Fact Table
- songplays 
Records log data associated with song plays i.e. records with page NextSong
(songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)

### Dimension Tables
- users 
Users in the app
(user_id, first_name, last_name, gender, level)
- songs
Songs in music database
(song_id, title, artist_id, year, duration)
- artists
Artists in music database
(artist_id, name, location, lattitude, longitude)
- time 
Timestamps of records in songplays broken down into specific units
(start_time, hour, day, week, month, year, weekday)
